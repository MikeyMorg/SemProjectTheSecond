{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enforce copy on write\n",
    "pd.options.mode.copy_on_write = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data far too large to upload - download from https://www.cdc.gov/brfss/annual_data/annual_2014.html (SAS format)\n",
    "\n",
    "\n",
    "Ensure file name is LLCP2014.XPT (i had issues with file saving with extra space at end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   _STATE  FMONTH        IDATE IMONTH   IDAY    IYEAR  DISPCODE         SEQNO  \\\n",
      "0     1.0     1.0  b'01172014'  b'01'  b'17'  b'2014'    1100.0  2.014000e+09   \n",
      "1     1.0     1.0  b'01072014'  b'01'  b'07'  b'2014'    1100.0  2.014000e+09   \n",
      "2     1.0     1.0  b'01092014'  b'01'  b'09'  b'2014'    1100.0  2.014000e+09   \n",
      "3     1.0     1.0  b'01072014'  b'01'  b'07'  b'2014'    1100.0  2.014000e+09   \n",
      "4     1.0     1.0  b'01162014'  b'01'  b'16'  b'2014'    1100.0  2.014000e+09   \n",
      "\n",
      "           _PSU  CTELENUM  ...  _FOBTFS  _CRCREC  _AIDTST3  _IMPEDUC  \\\n",
      "0  2.014000e+09       1.0  ...      2.0      1.0       2.0       5.0   \n",
      "1  2.014000e+09       1.0  ...      2.0      2.0       2.0       4.0   \n",
      "2  2.014000e+09       1.0  ...      2.0      2.0       2.0       6.0   \n",
      "3  2.014000e+09       1.0  ...      2.0      1.0       2.0       6.0   \n",
      "4  2.014000e+09       1.0  ...      2.0      1.0       2.0       5.0   \n",
      "\n",
      "   _IMPMRTL  _IMPHOME  RCSBRAC1  RCSRACE1  RCHISLA1  RCSBIRTH  \n",
      "0       1.0       1.0       NaN       b''       b''       b''  \n",
      "1       1.0       1.0       NaN       b''       b''       b''  \n",
      "2       1.0       1.0       NaN       b''       b''       b''  \n",
      "3       3.0       1.0       NaN       b''       b''       b''  \n",
      "4       1.0       1.0       NaN       b''       b''       b''  \n",
      "\n",
      "[5 rows x 279 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(464664, 279)"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwd = Path().cwd()\n",
    "project_folder = cwd.parent\n",
    "data_path = Path(\"data/LLCP2014.XPT\")\n",
    "file = project_folder / data_path\n",
    "\n",
    "if not file.exists():\n",
    "    raise FileNotFoundError(\"Data files not found. Please ensure the data files are in the correct directory.\")\n",
    "\n",
    "df = pd.read_sas(file)\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = Path().cwd()\n",
    "project_folder = cwd.parent\n",
    "data_path = Path(\"data/LLCP2014.XPT\")\n",
    "file = project_folder / data_path\n",
    "\n",
    "if not file.exists():\n",
    "    raise FileNotFoundError(\"Data files not found. Please ensure the data files are in the correct directory.\")\n",
    "\n",
    "df = pd.read_sas(file)\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I define variables deemed relevant to the data analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing from 2014 df: []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(464664, 23)"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Minimal 2014 BRFSS variable groups ---\n",
    "\n",
    "# Sleep exposure\n",
    "sleep_vars_2014 = [\n",
    "    \"SLEPTIM1\",       # hours of sleep in a 24-hour period\n",
    "]\n",
    "\n",
    "# Core demographics (sex, age, SES, race/ethnicity, geography)\n",
    "demo_vars_2014 = [\n",
    "    \"SEX\",            # sex\n",
    "    \"_AGEG5YR\",       # 5-year age groups\n",
    "    \"EDUCA\",          # education\n",
    "    \"INCOME2\",        # household income categories\n",
    "    \"_RACEGR3\",       # race groups\n",
    "    \"_HISPANC\",       # hispanic ethnicity\n",
    "    \"_STATE\",         # state FIPS\n",
    "]\n",
    "\n",
    "# Body size \n",
    "bmi_vars_2014 = [\n",
    "    \"_BMI5\",          # BMI *100\n",
    "    \"_BMI5CAT\",       # BMI categories\n",
    "]\n",
    "\n",
    "# Physical activity (simple indicator of any leisure-time PA)\n",
    "activity_vars_2014 = [\n",
    "    \"_TOTINDA\",       # any vs no leisure-time physical activity\n",
    "]\n",
    "\n",
    "# Smoking & alcohol: compact, derived indicators plus binge behavior\n",
    "smoking_alcohol_vars_2014 = [\n",
    "    \"_SMOKER3\",       # 4-level smoking status\n",
    "    \"_RFSMOK3\",       # current smoker risk indicator\n",
    "    \"DRNK3GE5\",       # binge drinking (yes/no)\n",
    "    \"_RFBING5\",       # binge drinking flag (derived)\n",
    "]\n",
    "\n",
    "# General health / mental health\n",
    "health_status_vars_2014 = [\n",
    "    \"GENHLTH\",        # self-rated health\n",
    "    \"MENTHLTH\",       # days mental health not good (0–30)\n",
    "]\n",
    "\n",
    "# Major chronic conditions (keep a small, high-yield set)\n",
    "chronic_condition_vars_2014 = [\n",
    "    \"CVDINFR4\",       # ever heart attack\n",
    "    \"CVDSTRK3\",       # ever stroke\n",
    "    \"CHCCOPD1\",       # COPD/emphysema/chronic bronchitis\n",
    "    \"ASTHMA3\",        # ever asthma\n",
    "    \"DIABETE3\",       # diabetes\n",
    "    \"ADDEPEV2\",       # depressive disorder\n",
    "]\n",
    "\n",
    "# Combine into a candidate list and subset dataframe\n",
    "candidate_cols_2014 = (\n",
    "    sleep_vars_2014\n",
    "    + demo_vars_2014\n",
    "    + bmi_vars_2014\n",
    "    + activity_vars_2014\n",
    "    + smoking_alcohol_vars_2014\n",
    "    + health_status_vars_2014\n",
    "    + chronic_condition_vars_2014\n",
    ")\n",
    "\n",
    "# Keep only those that actually exist in loaded 2014 dataframe\n",
    "relevant_cols_2014 = [c for c in candidate_cols_2014 if c in df.columns]\n",
    "\n",
    "print(\"Missing from 2014 df:\", [c for c in candidate_cols_2014 if c not in df.columns])\n",
    "\n",
    "df_reduced_2014 = df[relevant_cols_2014].copy()\n",
    "\n",
    "df_reduced_2014.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invalidate values outside possible range, create a short sleep indicator from datapoints with sleep < 7 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SLEPTIM1: valid 1–24; 77 = don't know, 99 = refused\n",
    "if \"SLEPTIM1\" in df_reduced_2014.columns:\n",
    "    df_reduced_2014[\"sleep_hours\"] = (\n",
    "        df_reduced_2014[\"SLEPTIM1\"]\n",
    "        .replace({77: np.nan, 99: np.nan})\n",
    "        .astype(\"float\")\n",
    "    )\n",
    "\n",
    "    # remove impossible values\n",
    "    df_reduced_2014.loc[(df_reduced_2014[\"sleep_hours\"] < 1) | (df_reduced_2014[\"sleep_hours\"] > 24), \"sleep_hours\"] = np.nan\n",
    "\n",
    "    # Short sleep indicator (< 7 hours)\n",
    "    df_reduced_2014[\"short_sleep\"] = np.where(df_reduced_2014[\"sleep_hours\"] < 7, 1, 0)\n",
    "    df_reduced_2014.loc[df_reduced_2014[\"sleep_hours\"].isna(), \"short_sleep\"] = np.nan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjust BMI from _BMI5, and account for missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BMI from _BMI5 (BMI*100, 9999 = missing)\n",
    "if \"_BMI5\" in df_reduced_2014.columns:\n",
    "    df_reduced_2014[\"bmi\"] = df_reduced_2014[\"_BMI5\"].astype(\"float\")\n",
    "    df_reduced_2014.loc[df_reduced_2014[\"bmi\"] >= 9999, \"bmi\"] = np.nan\n",
    "    df_reduced_2014[\"bmi\"] = df_reduced_2014[\"bmi\"] / 100.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign sex to a binary value. \n",
    "\n",
    "Assign education values to one of 3 values to make it ordinal. \n",
    "\n",
    "Create binary values for low income, race (white) and race (hispanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sex: 1 = male, 2 = female, 7/9 = missing\n",
    "if \"SEX\" in df_reduced_2014.columns:\n",
    "    sex_clean = df_reduced_2014[\"SEX\"].replace({7: np.nan, 9: np.nan})\n",
    "    df_reduced_2014[\"sex_male\"] = np.where(sex_clean == 1, 1,\n",
    "                       np.where(sex_clean == 2, 0, np.nan))\n",
    "\n",
    "# Education (EDUCA: 1–6 valid, 9 = DK/refused)\n",
    "if \"EDUCA\" in df_reduced_2014.columns:\n",
    "    edu_clean = df_reduced_2014[\"EDUCA\"].replace({9: np.nan})\n",
    "    # 0 = ≤HS, 1 = some college, 2 = college+\n",
    "    df_reduced_2014[\"educ_3cat\"] = np.select(\n",
    "        [\n",
    "            edu_clean.isin([1, 2, 3]),   # Never attended – HS grad\n",
    "            edu_clean.isin([4, 5]),      # Some college/technical school\n",
    "            edu_clean == 6,              # College grad+\n",
    "        ],\n",
    "        [0, 1, 2],\n",
    "        default=np.nan\n",
    "    )\n",
    "\n",
    "# Income (INCOME2: 1–8, 77/99 = missing)\n",
    "if \"INCOME2\" in df_reduced_2014.columns:\n",
    "    inc_clean = df_reduced_2014[\"INCOME2\"].replace({77: np.nan, 99: np.nan})\n",
    "    # Low income (<$35k: 1–4), high income (5–8)\n",
    "    df_reduced_2014[\"low_income\"] = np.where(inc_clean.isin([1, 2, 3, 4]), 1,\n",
    "                         np.where(inc_clean.isin([5, 6, 7, 8]), 0, np.nan))\n",
    "\n",
    "# Race/ethnicity: _RACEGR3 (1=White NH, 2=Black NH, 3=Other NH, 4=Multiracial NH, 5=Hispanic)\n",
    "if \"_RACEGR3\" in df_reduced_2014.columns:\n",
    "    race_clean = df_reduced_2014[\"_RACEGR3\"].replace({9: np.nan})\n",
    "    df_reduced_2014[\"race_white_nh\"] = np.where(race_clean == 1, 1,\n",
    "                            np.where(race_clean.isin([2, 3, 4, 5]), 0, np.nan))\n",
    "    df_reduced_2014[\"race_hispanic\"] = np.where(race_clean == 5, 1,\n",
    "                            np.where(race_clean.isin([1, 2, 3, 4]), 0, np.nan))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "take leisure physical activity and assign binary values for two different designations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _TOTINDA: 1 = any leisure-time PA, 2 = none, 9 = DK/refused\n",
    "if \"_TOTINDA\" in df_reduced_2014.columns:\n",
    "    pa_clean = df_reduced_2014[\"_TOTINDA\"].replace({9: np.nan})\n",
    "    df_reduced_2014[\"any_leisure_pa\"] = np.where(pa_clean == 1, 1, np.where(pa_clean == 2, 0, np.nan))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjust smoker categories to two binary categories. Smoker ever for individuals that have smoked before and smoker current for individuals that currently smoke. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _SMOKER3: 1=current every day, 2=current some days, 3=former, 4=never, 9=DK/ref\n",
    "if \"_SMOKER3\" in df_reduced_2014.columns:\n",
    "    sm_clean = df_reduced_2014[\"_SMOKER3\"].replace({9: np.nan})\n",
    "    df_reduced_2014[\"smoker_current\"] = sm_clean\n",
    "    df_reduced_2014[\"smoker_ever\"] = np.where(sm_clean.isin([1, 2, 3]), 1,\n",
    "                          np.where(sm_clean == 4, 0, np.nan))\n",
    "\n",
    "# _RFBING5: 1 = no binge, 2 = binge, 9 = DK/ref\n",
    "if \"_RFBING5\" in df_reduced_2014.columns:\n",
    "    binge_clean = df_reduced_2014[\"_RFBING5\"].replace({9: np.nan})\n",
    "    df_reduced_2014[\"binge_drink\"] = np.where(binge_clean == 2, 1,\n",
    "                          np.where(binge_clean == 1, 0, np.nan))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "assign the general health rating to one of two categories, good health and poor health. \n",
    "\n",
    "assign mental_unhealthy days to valid values of METNTHLTH column, and assign a binary value for poor mental health days being frequent (>=14) or infrequent (<14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENHLTH: 1=excellent ... 5=poor, 7/9 = DK/ref\n",
    "if \"GENHLTH\" in df_reduced_2014.columns:\n",
    "    gh_clean = df_reduced_2014[\"GENHLTH\"].replace({7: np.nan, 9: np.nan})\n",
    "    df_reduced_2014[\"fairpoor_health\"] = np.where(gh_clean.isin([4, 5]), 1,\n",
    "                              np.where(gh_clean.isin([1, 2, 3]), 0, np.nan))\n",
    "\n",
    "# MENTHLTH: 0–30, 88 = none, 77/99 = DK/ref\n",
    "if \"MENTHLTH\" in df_reduced_2014.columns:\n",
    "    mental = df_reduced_2014[\"MENTHLTH\"].replace({77: np.nan, 99: np.nan, 88: 0}).astype(\"float\")\n",
    "    df_reduced_2014[\"mental_unhealthy_days\"] = mental\n",
    "    df_reduced_2014[\"frequent_mental_distress\"] = np.where(mental >= 14, 1,\n",
    "                                       np.where(mental < 14, 0, np.nan))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "take all of the diagnosis variables and store them as 0 for never having had, and 1 for having had. \n",
    "\n",
    "Apply the same logic to different diabetes categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary ever-diagnosed variables: 1=yes, 2=no, 7/9=missing\n",
    "for var in [\"CVDINFR4\", \"CVDSTRK3\", \"CHCCOPD1\", \"ASTHMA3\", \"ADDEPEV2\"]:\n",
    "    if var in df_reduced_2014.columns:\n",
    "        x = df_reduced_2014[var].replace({7: np.nan, 9: np.nan})\n",
    "        new_name = var.lower() + \"_ever\"\n",
    "        df_reduced_2014[new_name] = np.where(x == 1, 1,\n",
    "                         np.where(x == 2, 0, np.nan))\n",
    "\n",
    "# DIABETE3: 1=yes, 2=yes (pregnant), 3=no, 4=pre-diabetes; 7/9=missing\n",
    "if \"DIABETE3\" in df_reduced_2014.columns:\n",
    "    dia = df_reduced_2014[\"DIABETE3\"].replace({7: np.nan, 9: np.nan})\n",
    "    df_reduced_2014[\"diabetes_any\"] = np.where(dia.isin([1, 2]), 1,\n",
    "                           np.where(dia.isin([3, 4]), 0, np.nan))\n",
    "    df_reduced_2014[\"prediabetes\"] = np.where(dia == 4, 1,\n",
    "                          np.where(dia.isin([1, 2, 3]), 0, np.nan))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove NaN sleep hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(458172, 45)"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only respondents with valid sleep_hours\n",
    "if \"sleep_hours\" in df_reduced_2014.columns:\n",
    "    df_reduced_2014 = df_reduced_2014[df_reduced_2014[\"sleep_hours\"].notna()].copy()\n",
    "\n",
    "df_reduced_2014.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rename technical names for diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced_2014 = df_reduced_2014.rename(columns={\n",
    "    \"cvdinfr4_ever\": \"heartattack_ever\",\n",
    "    \"cvdstrk3_ever\": \"stroke_ever\",\n",
    "    \"chccopd1_ever\": \"lungdisease_ever\",\n",
    "    \"addepev2_ever\": \"depression_ever\",\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['SLEPTIM1', 'SEX', '_AGEG5YR', 'EDUCA', 'INCOME2', '_RACEGR3',\n",
      "       '_HISPANC', '_STATE', '_BMI5', '_BMI5CAT', '_TOTINDA', '_SMOKER3',\n",
      "       '_RFSMOK3', 'DRNK3GE5', '_RFBING5', 'GENHLTH', 'MENTHLTH', 'CVDINFR4',\n",
      "       'CVDSTRK3', 'CHCCOPD1', 'ASTHMA3', 'DIABETE3', 'ADDEPEV2',\n",
      "       'sleep_hours', 'short_sleep', 'bmi', 'sex_male', 'educ_3cat',\n",
      "       'low_income', 'race_white_nh', 'race_hispanic', 'any_leisure_pa',\n",
      "       'smoker_current', 'smoker_ever', 'binge_drink', 'fairpoor_health',\n",
      "       'mental_unhealthy_days', 'frequent_mental_distress', 'heartattack_ever',\n",
      "       'stroke_ever', 'lungdisease_ever', 'asthma3_ever', 'depression_ever',\n",
      "       'diabetes_any', 'prediabetes'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_reduced_2014.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establish final columns that will be used in modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sleep_hours  short_sleep  sex_male  _AGEG5YR  educ_3cat  low_income  \\\n",
      "0          9.0          0.0       0.0       9.0        1.0         0.0   \n",
      "1          6.0          1.0       1.0      11.0        1.0         1.0   \n",
      "2          8.0          0.0       1.0       7.0        2.0         0.0   \n",
      "3          8.0          0.0       0.0      10.0        2.0         0.0   \n",
      "4          8.0          0.0       0.0      10.0        1.0         1.0   \n",
      "\n",
      "   race_white_nh  race_hispanic  any_leisure_pa  smoker_current  binge_drink  \\\n",
      "0            0.0            0.0             0.0             3.0          0.0   \n",
      "1            1.0            0.0             1.0             4.0          0.0   \n",
      "2            1.0            0.0             1.0             3.0          0.0   \n",
      "3            1.0            0.0             0.0             4.0          0.0   \n",
      "4            1.0            0.0             0.0             4.0          0.0   \n",
      "\n",
      "     bmi  fairpoor_health  frequent_mental_distress  heartattack_ever  \\\n",
      "0  25.51              1.0                       0.0               1.0   \n",
      "1  24.95              0.0                       1.0               0.0   \n",
      "2  37.30              0.0                       0.0               0.0   \n",
      "3  54.42              0.0                       NaN               0.0   \n",
      "4  37.12              0.0                       0.0               0.0   \n",
      "\n",
      "   stroke_ever  lungdisease_ever  asthma3_ever  depression_ever  diabetes_any  \n",
      "0          1.0               1.0           0.0              0.0           1.0  \n",
      "1          1.0               1.0           0.0              1.0           0.0  \n",
      "2          0.0               0.0           0.0              0.0           0.0  \n",
      "3          0.0               1.0           1.0              1.0           1.0  \n",
      "4          0.0               0.0           0.0              0.0           0.0  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(458172, 20)"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_columns = [\n",
    "    # Sleep\n",
    "    \"sleep_hours\",\n",
    "    \"short_sleep\",\n",
    "\n",
    "    # Demographics\n",
    "    \"sex_male\",\n",
    "    \"_AGEG5YR\",\n",
    "    \"educ_3cat\",\n",
    "    \"low_income\",\n",
    "    \"race_white_nh\",\n",
    "    \"race_hispanic\",\n",
    "    \n",
    "    # Health behaviors\n",
    "    \"any_leisure_pa\",\n",
    "    \"smoker_current\",\n",
    "    \"binge_drink\",\n",
    "\n",
    "    # BMI\n",
    "    \"bmi\",\n",
    "\n",
    "    # Health status\n",
    "    \"fairpoor_health\",\n",
    "    \"frequent_mental_distress\",\n",
    "\n",
    "    # Chronic conditions\n",
    "    \"heartattack_ever\",\n",
    "    \"stroke_ever\",\n",
    "    \"lungdisease_ever\",\n",
    "    \"asthma3_ever\",\n",
    "    \"depression_ever\",\n",
    "    \"diabetes_any\",\n",
    "]\n",
    "\n",
    "df_clean = df_reduced_2014[final_columns].copy()\n",
    "print(df_clean.head())\n",
    "\n",
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is clean (i think) and ready to explore!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric: ['bmi']\n",
      "Ordinal: ['_AGEG5YR', 'educ_3cat', 'smoker_current']\n",
      "Binary: ['sex_male', 'race_white_nh', 'race_hispanic', 'any_leisure_pa', 'binge_drink', 'fairpoor_health', 'frequent_mental_distress', 'heartattack_ever', 'stroke_ever', 'lungdisease_ever', 'asthma3_ever', 'depression_ever', 'diabetes_any']\n"
     ]
    }
   ],
   "source": [
    "# Numeric (continuous)\n",
    "numeric_features = [\n",
    "    \"bmi\",\n",
    "]\n",
    "numeric_features = [c for c in numeric_features if c in df_clean.columns]\n",
    "\n",
    "# Ordinal (ordered categories)\n",
    "ordinal_features = [\n",
    "    \"_AGEG5YR\",   # 5-year age groups\n",
    "    \"educ_3cat\",  # 0 <=HS, 1 some college, 2 college+\n",
    "    \"smoker_current\", # 1 every day, 2 some days, 3 before, 4 never\n",
    "]\n",
    "ordinal_features = [c for c in ordinal_features if c in df_clean.columns]\n",
    "\n",
    "# Binary indicators (already 0/1; pass through)\n",
    "binary_features = [\n",
    "    \"sex_male\",\n",
    "    \"race_white_nh\",\n",
    "    \"race_hispanic\",\n",
    "    \"any_leisure_pa\",\n",
    "    \"binge_drink\",\n",
    "    \"obese\",\n",
    "    \"fairpoor_health\",\n",
    "    \"frequent_mental_distress\",\n",
    "    \"heartattack_ever\",\n",
    "    \"stroke_ever\",\n",
    "    \"lungdisease_ever\",\n",
    "    \"asthma3_ever\",\n",
    "    \"depression_ever\",\n",
    "    \"diabetes_any\",\n",
    "]\n",
    "binary_features = [c for c in binary_features if c in df_clean.columns]\n",
    "\n",
    "print(\"Numeric:\", numeric_features)\n",
    "print(\"Ordinal:\", ordinal_features)\n",
    "print(\"Binary:\", binary_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(458172, 20)"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NaN counts for numeric features:\n",
      "bmi    29548\n",
      "dtype: int64\n",
      "\n",
      "NaN counts for ordinal features:\n",
      "_AGEG5YR              0\n",
      "educ_3cat          3570\n",
      "smoker_current    20584\n",
      "dtype: int64\n",
      "\n",
      "NaN counts for binary features:\n",
      "sex_male                        0\n",
      "race_white_nh                7542\n",
      "race_hispanic                7542\n",
      "any_leisure_pa               1628\n",
      "binge_drink                 28557\n",
      "fairpoor_health              1515\n",
      "frequent_mental_distress     7211\n",
      "heartattack_ever             2155\n",
      "stroke_ever                  1260\n",
      "lungdisease_ever             2330\n",
      "asthma3_ever                 1414\n",
      "depression_ever              1922\n",
      "diabetes_any                  777\n",
      "dtype: int64\n",
      "{'numeric': np.int64(29548), 'ordinal': np.int64(24154), 'binary': np.int64(63853)}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "feature_groups = {\n",
    "    \"numeric\": numeric_features,\n",
    "    \"ordinal\": ordinal_features,\n",
    "    \"binary\": binary_features,\n",
    "}\n",
    "\n",
    "nan_counts = {\n",
    "    group: df_clean[cols].isna().sum()\n",
    "    for group, cols in feature_groups.items()\n",
    "}\n",
    "\n",
    "for group, counts in nan_counts.items():\n",
    "    print(f\"\\nNaN counts for {group} features:\")\n",
    "    print(counts)\n",
    "\n",
    "total_nan_per_group = {\n",
    "    group: df_clean[cols].isna().sum().sum()\n",
    "    for group, cols in feature_groups.items()\n",
    "}\n",
    "\n",
    "print(total_nan_per_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NUMERIC FEATURES\n",
      "     num_missing  missing_ratio\n",
      "bmi        29548       0.064491\n",
      "\n",
      "ORDINAL FEATURES\n",
      "                num_missing  missing_ratio\n",
      "_AGEG5YR                  0       0.000000\n",
      "educ_3cat              3570       0.007792\n",
      "smoker_current        20584       0.044926\n",
      "\n",
      "BINARY FEATURES\n",
      "                          num_missing  missing_ratio\n",
      "sex_male                            0       0.000000\n",
      "race_white_nh                    7542       0.016461\n",
      "race_hispanic                    7542       0.016461\n",
      "any_leisure_pa                   1628       0.003553\n",
      "binge_drink                     28557       0.062328\n",
      "fairpoor_health                  1515       0.003307\n",
      "frequent_mental_distress         7211       0.015739\n",
      "heartattack_ever                 2155       0.004703\n",
      "stroke_ever                      1260       0.002750\n",
      "lungdisease_ever                 2330       0.005085\n",
      "asthma3_ever                     1414       0.003086\n",
      "depression_ever                  1922       0.004195\n",
      "diabetes_any                      777       0.001696\n"
     ]
    }
   ],
   "source": [
    "for group, cols in feature_groups.items():\n",
    "    print(f\"\\n{group.upper()} FEATURES\")\n",
    "    \n",
    "    # number of NaNs per feature\n",
    "    nan_counts = df_clean[cols].isna().sum()\n",
    "    \n",
    "    # ratio of NaNs per feature\n",
    "    nan_ratios = df_clean[cols].isna().mean()\n",
    "    \n",
    "    # combine into a single DataFrame for display\n",
    "    summary = pd.DataFrame({\n",
    "        \"num_missing\": nan_counts,\n",
    "        \"missing_ratio\": nan_ratios\n",
    "    })\n",
    "    \n",
    "    print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(407198, 20)\n"
     ]
    }
   ],
   "source": [
    "cols_to_filter = [\"bmi\", \"smoker_current\", \"binge_drink\"]\n",
    "\n",
    "df_filtered = df_clean.dropna(subset=cols_to_filter)\n",
    "\n",
    "print(df_filtered.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NaN counts for numeric features:\n",
      "bmi    0\n",
      "dtype: int64\n",
      "\n",
      "NaN counts for ordinal features:\n",
      "_AGEG5YR            0\n",
      "educ_3cat         683\n",
      "smoker_current      0\n",
      "dtype: int64\n",
      "\n",
      "NaN counts for binary features:\n",
      "sex_male                       0\n",
      "race_white_nh               5340\n",
      "race_hispanic               5340\n",
      "any_leisure_pa               755\n",
      "binge_drink                    0\n",
      "fairpoor_health             1215\n",
      "frequent_mental_distress    5698\n",
      "heartattack_ever            1714\n",
      "stroke_ever                  989\n",
      "lungdisease_ever            1865\n",
      "asthma3_ever                1102\n",
      "depression_ever             1453\n",
      "diabetes_any                 522\n",
      "dtype: int64\n",
      "{'numeric': np.int64(0), 'ordinal': np.int64(683), 'binary': np.int64(25993)}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "feature_groups = {\n",
    "    \"numeric\": numeric_features,\n",
    "    \"ordinal\": ordinal_features,\n",
    "    \"binary\": binary_features,\n",
    "}\n",
    "\n",
    "nan_counts = {\n",
    "    group: df_filtered[cols].isna().sum()\n",
    "    for group, cols in feature_groups.items()\n",
    "}\n",
    "\n",
    "for group, counts in nan_counts.items():\n",
    "    print(f\"\\nNaN counts for {group} features:\")\n",
    "    print(counts)\n",
    "\n",
    "total_nan_per_group = {\n",
    "    group: df_filtered[cols].isna().sum().sum()\n",
    "    for group, cols in feature_groups.items()\n",
    "}\n",
    "\n",
    "print(total_nan_per_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " NUMERIC FEATURES\n",
      "     num_missing  missing_ratio\n",
      "bmi            0            0.0\n",
      "\n",
      " ORDINAL FEATURES\n",
      "                num_missing  missing_ratio\n",
      "_AGEG5YR                  0       0.000000\n",
      "educ_3cat               683       0.001677\n",
      "smoker_current            0       0.000000\n",
      "\n",
      " BINARY FEATURES\n",
      "                          num_missing  missing_ratio\n",
      "sex_male                            0       0.000000\n",
      "race_white_nh                    5340       0.013114\n",
      "race_hispanic                    5340       0.013114\n",
      "any_leisure_pa                    755       0.001854\n",
      "binge_drink                         0       0.000000\n",
      "fairpoor_health                  1215       0.002984\n",
      "frequent_mental_distress         5698       0.013993\n",
      "heartattack_ever                 1714       0.004209\n",
      "stroke_ever                       989       0.002429\n",
      "lungdisease_ever                 1865       0.004580\n",
      "asthma3_ever                     1102       0.002706\n",
      "depression_ever                  1453       0.003568\n",
      "diabetes_any                      522       0.001282\n"
     ]
    }
   ],
   "source": [
    "for group, cols in feature_groups.items():\n",
    "    print(f\"\\n {group.upper()} FEATURES\")\n",
    "    \n",
    "    # number of NaNs per feature\n",
    "    nan_counts = df_filtered[cols].isna().sum()\n",
    "    \n",
    "    # ratio of NaNs per feature\n",
    "    nan_ratios = df_filtered[cols].isna().mean()\n",
    "    \n",
    "    # combine into a single DataFrame for display\n",
    "    summary = pd.DataFrame({\n",
    "        \"num_missing\": nan_counts,\n",
    "        \"missing_ratio\": nan_ratios\n",
    "    })\n",
    "    \n",
    "    print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(407198, 20)"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "short_sleep\n",
      "0.0    278988\n",
      "1.0    128210\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "target = \"short_sleep\"\n",
    "\n",
    "print(df_filtered[target].value_counts())\n",
    "\n",
    "df_model = df_filtered[df_filtered[target].notna()].copy()\n",
    "\n",
    "X = df_model.drop(columns=[target])\n",
    "y = df_model[target]\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.25,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")), # give the numeric values a common value if missing\n",
    "    (\"scaler\", StandardScaler()),\n",
    "])\n",
    "\n",
    "ordinal_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")), #give the ordinal values a common value if missing\n",
    "    (\"scaler\", StandardScaler()),\n",
    "])\n",
    "\n",
    "binary_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")), #give the binary values the most common value if missing \n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"ord\", ordinal_transformer, ordinal_features),\n",
    "        (\"bin\", binary_transformer, binary_features),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iangower/Documents/GitHub/CS577/SemProjectTheSecond/venv/lib/python3.9/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/iangower/Documents/GitHub/CS577/SemProjectTheSecond/venv/lib/python3.9/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/iangower/Documents/GitHub/CS577/SemProjectTheSecond/venv/lib/python3.9/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/iangower/Documents/GitHub/CS577/SemProjectTheSecond/venv/lib/python3.9/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/iangower/Documents/GitHub/CS577/SemProjectTheSecond/venv/lib/python3.9/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/iangower/Documents/GitHub/CS577/SemProjectTheSecond/venv/lib/python3.9/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.67      0.71     69747\n",
      "         1.0       0.43      0.53      0.47     32053\n",
      "\n",
      "    accuracy                           0.63    101800\n",
      "   macro avg       0.59      0.60      0.59    101800\n",
      "weighted avg       0.65      0.63      0.64    101800\n",
      "\n",
      "Confusion matrix:\n",
      " [[46604 23143]\n",
      " [14937 17116]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iangower/Documents/GitHub/CS577/SemProjectTheSecond/venv/lib/python3.9/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/iangower/Documents/GitHub/CS577/SemProjectTheSecond/venv/lib/python3.9/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/iangower/Documents/GitHub/CS577/SemProjectTheSecond/venv/lib/python3.9/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    }
   ],
   "source": [
    "log_reg_pipeline = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"clf\", LogisticRegression(\n",
    "        max_iter=500,\n",
    "        class_weight=\"balanced\",  # helps with class imbalance\n",
    "        n_jobs=-1\n",
    "    )),\n",
    "])\n",
    "\n",
    "log_reg_pipeline.fit(X_train, y_train)\n",
    "y_pred_lr = log_reg_pipeline.predict(X_val)\n",
    "\n",
    "print(\"Logistic Regression\")\n",
    "print(classification_report(y_val, y_pred_lr))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_val, y_pred_lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.74      0.73     69747\n",
      "         1.0       0.38      0.34      0.35     32053\n",
      "\n",
      "    accuracy                           0.61    101800\n",
      "   macro avg       0.54      0.54      0.54    101800\n",
      "weighted avg       0.60      0.61      0.61    101800\n",
      "\n",
      "Confusion matrix:\n",
      " [[51852 17895]\n",
      " [21298 10755]]\n"
     ]
    }
   ],
   "source": [
    "rf_pipeline = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"clf\", RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=None,\n",
    "        max_features= 'sqrt',\n",
    "        class_weight=\"balanced\",  # also helps with imbalance\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )),\n",
    "])\n",
    "\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "y_pred_rf = rf_pipeline.predict(X_val)\n",
    "\n",
    "print(\"Random Forest\")\n",
    "print(classification_report(y_val, y_pred_rf))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_val, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>num__bmi</td>\n",
       "      <td>0.639661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ord___AGEG5YR</td>\n",
       "      <td>0.118650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ord__smoker_current</td>\n",
       "      <td>0.037900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ord__educ_3cat</td>\n",
       "      <td>0.026949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bin__sex_male</td>\n",
       "      <td>0.018745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bin__frequent_mental_distress</td>\n",
       "      <td>0.016864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bin__fairpoor_health</td>\n",
       "      <td>0.016315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>bin__diabetes_any</td>\n",
       "      <td>0.016103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bin__any_leisure_pa</td>\n",
       "      <td>0.014782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bin__depression_ever</td>\n",
       "      <td>0.014712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bin__race_white_nh</td>\n",
       "      <td>0.014307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bin__binge_drink</td>\n",
       "      <td>0.014066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bin__asthma3_ever</td>\n",
       "      <td>0.012745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bin__heartattack_ever</td>\n",
       "      <td>0.011237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bin__lungdisease_ever</td>\n",
       "      <td>0.011169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bin__stroke_ever</td>\n",
       "      <td>0.010181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bin__race_hispanic</td>\n",
       "      <td>0.005614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          feature  importance\n",
       "0                        num__bmi    0.639661\n",
       "1                   ord___AGEG5YR    0.118650\n",
       "3             ord__smoker_current    0.037900\n",
       "2                  ord__educ_3cat    0.026949\n",
       "4                   bin__sex_male    0.018745\n",
       "10  bin__frequent_mental_distress    0.016864\n",
       "9            bin__fairpoor_health    0.016315\n",
       "16              bin__diabetes_any    0.016103\n",
       "7             bin__any_leisure_pa    0.014782\n",
       "15           bin__depression_ever    0.014712\n",
       "5              bin__race_white_nh    0.014307\n",
       "8                bin__binge_drink    0.014066\n",
       "14              bin__asthma3_ever    0.012745\n",
       "11          bin__heartattack_ever    0.011237\n",
       "13          bin__lungdisease_ever    0.011169\n",
       "12               bin__stroke_ever    0.010181\n",
       "6              bin__race_hispanic    0.005614"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model = rf_pipeline.named_steps[\"clf\"]\n",
    "encoded_feature_names = rf_pipeline.named_steps[\"preprocess\"].get_feature_names_out()\n",
    "importances = rf_model.feature_importances_\n",
    "\n",
    "feat_imp = (\n",
    "    pd.DataFrame({\"feature\": encoded_feature_names, \"importance\": importances})\n",
    "      .sort_values(\"importance\", ascending=False)\n",
    ")\n",
    "\n",
    "feat_imp.head(20)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
